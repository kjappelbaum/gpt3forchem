{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinmaikjablonka/miniconda3/envs/gpt3/lib/python3.9/site-packages/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gpt3/lib/python3.9/site-packages/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gpt3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from gpt3forchem.data import get_photoswitch_data\n",
    "from gpt3forchem.input import create_single_property_forward_prompts\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gpt3forchem.api_wrappers import fine_tune, query_gpt3, extract_prediction, ensemble_fine_tune\n",
    "import time\n",
    "from pycm import ConfusionMatrix\n",
    "from gpt3forchem.baselines import GPRBaseline, compute_fragprints\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use([\"science\", \"nature\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_photoswitch_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = create_single_property_forward_prompts(\n",
    "    data,\n",
    "    \"wavelength_cat\",\n",
    "    {\"wavelength_cat\": \"transition wavelength\"},\n",
    "    representation_col=\"SMILES\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = prompts.sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts, test_prompts = train_test_split(\n",
    "    prompts, test_size=0.2, random_state=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning on 10 train files and 1 valid files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: kjappelbaum. Use `wandb login --relogin` to force relogin\n",
      "wandb: wandb version 0.13.2 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "wandb: Tracking run with wandb version 0.13.1\n",
      "wandb: Run data is saved locally in /Users/kevinmaikjablonka/git/kjappelbaum/gpt3forchem/experiments/wandb/run-20220901_123234-ft-2Sepg0SHBs4k7dBvEmETqr0M\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run ft-2Sepg0SHBs4k7dBvEmETqr0M\n",
      "wandb: â­ï¸ View project at https://wandb.ai/kjappelbaum/GPT-3\n",
      "wandb: ğŸš€ View run at https://wandb.ai/kjappelbaum/GPT-3/runs/ft-2Sepg0SHBs4k7dBvEmETqr0M\n",
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb:                                                                                \n",
      "wandb: \n",
      "wandb: Run history:\n",
      "wandb:             elapsed_examples â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "wandb:               elapsed_tokens â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "wandb:                training_loss â–ˆâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–„â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–\n",
      "wandb:   training_sequence_accuracy â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–â–â–ˆâ–â–â–ˆâ–â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–â–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆ\n",
      "wandb:      training_token_accuracy â–â–ˆâ–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–ˆâ–…â–…â–ˆâ–…â–…â–ˆâ–…â–ˆâ–ˆâ–…â–…â–ˆâ–ˆâ–ˆâ–ˆâ–…â–…â–ˆâ–…â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆ\n",
      "wandb:              validation_loss â–ˆâ–ˆâ–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–‚â–â–‚â–â–‚\n",
      "wandb: validation_sequence_accuracy â–â–â–â–â–ˆâ–â–ˆâ–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–â–ˆâ–â–â–ˆâ–ˆâ–â–â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–â–â–â–ˆâ–\n",
      "wandb:    validation_token_accuracy â–â–†â–†â–†â–ˆâ–†â–ˆâ–ˆâ–ˆâ–†â–ˆâ–†â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–†â–†â–ˆâ–†â–†â–ˆâ–ˆâ–†â–†â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–†â–†â–†â–ˆâ–†\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:             elapsed_examples 501.0\n",
      "wandb:               elapsed_tokens 25261.0\n",
      "wandb:             fine_tuned_model ada:ft-lsmoepfl-2022...\n",
      "wandb:                       status succeeded\n",
      "wandb:                training_loss 0.02519\n",
      "wandb:   training_sequence_accuracy 1.0\n",
      "wandb:      training_token_accuracy 1.0\n",
      "wandb:              validation_loss 0.06602\n",
      "wandb: validation_sequence_accuracy 1.0\n",
      "wandb:    validation_token_accuracy 1.0\n",
      "wandb: \n",
      "wandb: Synced ft-2Sepg0SHBs4k7dBvEmETqr0M: https://wandb.ai/kjappelbaum/GPT-3/runs/ft-2Sepg0SHBs4k7dBvEmETqr0M\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20220901_123234-ft-2Sepg0SHBs4k7dBvEmETqr0M/logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ wandb sync completed successfully\n"
     ]
    }
   ],
   "source": [
    "models = ensemble_fine_tune(train_prompts, test_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) ['ada:ft-lsmoepfl-2022-09-01-10-23-37']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gpt3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a4fa60962de90e73b5da8d67a44b01d2de04630d82b94b8db1f727a73d31e61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
