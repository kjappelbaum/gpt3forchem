diff --git a/experiments/08_explore_photoswitch_learning.ipynb b/experiments/08_explore_photoswitch_learning.ipynb
index 3d175d4..9120e04 100644
--- a/experiments/08_explore_photoswitch_learning.ipynb
+++ b/experiments/08_explore_photoswitch_learning.ipynb
@@ -33,19 +33,20 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from gpt3forchem.data import get_photoswitch_data\n",
-    "from gpt3forchem.input import create_single_property_forward_prompts\n",
-    "from sklearn.model_selection import train_test_split\n",
-    "from gpt3forchem.api_wrappers import fine_tune, query_gpt3, extract_prediction\n",
     "import time\n",
-    "from pycm import ConfusionMatrix\n",
-    "from gpt3forchem.baselines import GPRBaseline, compute_fragprints\n",
-    "import pandas as pd\n",
-    "import numpy as np\n",
     "\n",
     "import matplotlib.pyplot as plt\n",
+    "import numpy as np\n",
+    "import pandas as pd\n",
+    "from pycm import ConfusionMatrix\n",
+    "from sklearn.model_selection import train_test_split\n",
+    "\n",
+    "from gpt3forchem.api_wrappers import extract_prediction, fine_tune, query_gpt3\n",
+    "from gpt3forchem.baselines import GPRBaseline, compute_fragprints\n",
+    "from gpt3forchem.data import get_photoswitch_data\n",
+    "from gpt3forchem.input import create_single_property_forward_prompts\n",
     "\n",
-    "plt.style.use([\"science\", \"nature\"])\n"
+    "plt.style.use([\"science\", \"nature\"])"
    ]
   },
   {
diff --git a/experiments/11_try_deep_ensemble.ipynb b/experiments/11_try_deep_ensemble.ipynb
index 7aabd9e..195d0a6 100644
--- a/experiments/11_try_deep_ensemble.ipynb
+++ b/experiments/11_try_deep_ensemble.ipynb
@@ -12,27 +12,14 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 9,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "/Users/kevinmaikjablonka/miniconda3/envs/gpt3/lib/python3.9/site-packages/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
-      "  warn(\n",
-      "/Users/kevinmaikjablonka/miniconda3/envs/gpt3/lib/python3.9/site-packages/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
-      "  warn(\n",
-      "/Users/kevinmaikjablonka/miniconda3/envs/gpt3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
-      "  from .autonotebook import tqdm as notebook_tqdm\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "from gpt3forchem.data import get_photoswitch_data\n",
     "from gpt3forchem.input import create_single_property_forward_prompts\n",
     "from sklearn.model_selection import train_test_split\n",
-    "from gpt3forchem.api_wrappers import fine_tune, query_gpt3, extract_prediction, ensemble_fine_tune\n",
+    "from gpt3forchem.api_wrappers import fine_tune, query_gpt3, extract_prediction, ensemble_fine_tune, multiple_query_gpt3\n",
     "import time\n",
     "from pycm import ConfusionMatrix\n",
     "from gpt3forchem.baselines import GPRBaseline, compute_fragprints\n",
@@ -47,7 +34,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 3,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -56,7 +43,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 4,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -70,7 +57,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 12,
+   "execution_count": 5,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -79,7 +66,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": 6,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -90,89 +77,853 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 14,
+   "execution_count": 7,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Fine tuning on 10 train files and 1 valid files\n"
+      "Fine tuning on 5 train files and 5 valid files\n",
+      "Fine-tune ft-0sMbEhCOyzwtyDu4KXcCcWBQ has the status \"pending\" and will not be logged\n",
+      "ðŸŽ‰ wandb sync completed successfully\n",
+      "Fine-tune ft-0sMbEhCOyzwtyDu4KXcCcWBQ has the status \"pending\" and will not be logged\n",
+      "ðŸŽ‰ wandb sync completed successfully\n",
+      "Fine-tune ft-0sMbEhCOyzwtyDu4KXcCcWBQ has the status \"pending\" and will not be logged\n",
+      "ðŸŽ‰ wandb sync completed successfully\n",
+      "Uploaded file from run_files/2022-09-01-13-33-35_train__ensemble_2_125.jsonl: file-hq8u626g7lvBn2brPfG5oqr1\n",
+      "Uploaded file from run_files/2022-09-01-13-33-35_valid__ensemble_2_40.jsonl: file-TSWNDsqoAFdORx2gdgrvfpPy\n",
+      "Created fine-tune: ft-93BW8r44toCI0uGx7RGezjqu\n",
+      "Streaming events until fine-tuning is complete...\n",
+      "\n",
+      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
+      "[2022-09-01 13:33:44] Created fine-tune: ft-93BW8r44toCI0uGx7RGezjqu\n",
+      "\n",
+      "Stream interrupted (client disconnected).\n",
+      "To resume the stream, run:\n",
+      "\n",
+      "  openai api fine_tunes.follow -i ft-93BW8r44toCI0uGx7RGezjqu\n",
+      "\n",
+      " \n",
+      "Upload progress:   0%|          | 0.00/15.2k [00:00<?, ?it/s]\n",
+      "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15.2k/15.2k [00:00<00:00, 7.84Mit/s]\n",
+      "\n",
+      "Upload progress:   0%|          | 0.00/4.88k [00:00<?, ?it/s]\n",
+      "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.88k/4.88k [00:00<00:00, 6.13Mit/s]\n",
+      "\n",
+      "Uploaded file from run_files/2022-09-01-13-33-35_train__ensemble_3_125.jsonl: file-hGZ63CMW76bWNkrXgcwZjMIy\n",
+      "Uploaded file from run_files/2022-09-01-13-33-35_valid__ensemble_3_40.jsonl: file-LdkuvTXp4ylBQdRksKPFcLU3\n",
+      "Created fine-tune: ft-0sMbEhCOyzwtyDu4KXcCcWBQ\n",
+      "Streaming events until fine-tuning is complete...\n",
+      "\n",
+      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
+      "[2022-09-01 13:34:12] Created fine-tune: ft-0sMbEhCOyzwtyDu4KXcCcWBQ\n",
+      "\n",
+      "Stream interrupted (client disconnected).\n",
+      "To resume the stream, run:\n",
+      "\n",
+      "  openai api fine_tunes.follow -i ft-0sMbEhCOyzwtyDu4KXcCcWBQ\n",
+      "\n",
+      " \n",
+      "Upload progress:   0%|          | 0.00/15.0k [00:00<?, ?it/s]\n",
+      "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15.0k/15.0k [00:00<00:00, 11.3Mit/s]\n",
+      "\n",
+      "Upload progress:   0%|          | 0.00/4.88k [00:00<?, ?it/s]\n",
+      "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.88k/4.88k [00:00<00:00, 6.13Mit/s]\n",
+      "\n"
      ]
-    },
+    }
+   ],
+   "source": [
+    "models = ensemble_fine_tune(train_prompts, test_prompts, num_models=5)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 8,
+   "metadata": {},
+   "outputs": [
     {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "wandb: Currently logged in as: kjappelbaum. Use `wandb login --relogin` to force relogin\n",
-      "wandb: wandb version 0.13.2 is available!  To upgrade, please run:\n",
-      "wandb:  $ pip install wandb --upgrade\n",
-      "wandb: Tracking run with wandb version 0.13.1\n",
-      "wandb: Run data is saved locally in /Users/kevinmaikjablonka/git/kjappelbaum/gpt3forchem/experiments/wandb/run-20220901_123234-ft-2Sepg0SHBs4k7dBvEmETqr0M\n",
-      "wandb: Run `wandb offline` to turn off syncing.\n",
-      "wandb: Syncing run ft-2Sepg0SHBs4k7dBvEmETqr0M\n",
-      "wandb: â­ï¸ View project at https://wandb.ai/kjappelbaum/GPT-3\n",
-      "wandb: ðŸš€ View run at https://wandb.ai/kjappelbaum/GPT-3/runs/ft-2Sepg0SHBs4k7dBvEmETqr0M\n",
-      "wandb: Waiting for W&B process to finish... (success).\n",
-      "wandb:                                                                                \n",
-      "wandb: \n",
-      "wandb: Run history:\n",
-      "wandb:             elapsed_examples â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
-      "wandb:               elapsed_tokens â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
-      "wandb:                training_loss â–ˆâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–„â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–\n",
-      "wandb:   training_sequence_accuracy â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–â–â–ˆâ–â–â–ˆâ–â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–â–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆ\n",
-      "wandb:      training_token_accuracy â–â–ˆâ–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–ˆâ–…â–…â–ˆâ–…â–…â–ˆâ–…â–ˆâ–ˆâ–…â–…â–ˆâ–ˆâ–ˆâ–ˆâ–…â–…â–ˆâ–…â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆ\n",
-      "wandb:              validation_loss â–ˆâ–ˆâ–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–‚â–â–‚â–â–‚\n",
-      "wandb: validation_sequence_accuracy â–â–â–â–â–ˆâ–â–ˆâ–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–â–ˆâ–â–â–ˆâ–ˆâ–â–â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–â–â–â–ˆâ–\n",
-      "wandb:    validation_token_accuracy â–â–†â–†â–†â–ˆâ–†â–ˆâ–ˆâ–ˆâ–†â–ˆâ–†â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–†â–†â–ˆâ–†â–†â–ˆâ–ˆâ–†â–†â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–†â–†â–†â–ˆâ–†\n",
-      "wandb: \n",
-      "wandb: Run summary:\n",
-      "wandb:             elapsed_examples 501.0\n",
-      "wandb:               elapsed_tokens 25261.0\n",
-      "wandb:             fine_tuned_model ada:ft-lsmoepfl-2022...\n",
-      "wandb:                       status succeeded\n",
-      "wandb:                training_loss 0.02519\n",
-      "wandb:   training_sequence_accuracy 1.0\n",
-      "wandb:      training_token_accuracy 1.0\n",
-      "wandb:              validation_loss 0.06602\n",
-      "wandb: validation_sequence_accuracy 1.0\n",
-      "wandb:    validation_token_accuracy 1.0\n",
-      "wandb: \n",
-      "wandb: Synced ft-2Sepg0SHBs4k7dBvEmETqr0M: https://wandb.ai/kjappelbaum/GPT-3/runs/ft-2Sepg0SHBs4k7dBvEmETqr0M\n",
-      "wandb: Synced 6 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)\n",
-      "wandb: Find logs at: ./wandb/run-20220901_123234-ft-2Sepg0SHBs4k7dBvEmETqr0M/logs\n"
-     ]
-    },
+     "data": {
+      "text/plain": [
+       "(#5) ['ada:ft-lsmoepfl-2022-09-01-11-35-43','ada:ft-lsmoepfl-2022-09-01-11-37-42',None,None,'ada:ft-lsmoepfl-2022-09-01-11-39-37']"
+      ]
+     },
+     "execution_count": 8,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "models"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 17,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "completions =   multiple_query_gpt3(models, test_prompts)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 18,
+   "metadata": {},
+   "outputs": [
     {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "ðŸŽ‰ wandb sync completed successfully\n"
-     ]
+     "data": {
+      "text/plain": [
+       "[{'choices': [<OpenAIObject at 0x2967e40e0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 0,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d4e00> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 1,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d4ea0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 2,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d4130> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 3,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d70e0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 4,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@@=@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d7090> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 5,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d72c0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 6,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d74a0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 7,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@### 2@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d7d10> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 8,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@### 2@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d79f0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 9,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d7f40> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 10,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967f8860> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 11,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967f8770> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 12,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@### 2@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967f8680> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 13,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967f8180> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 14,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 1@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b7310> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 15,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b74f0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 16,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b75e0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 17,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b76d0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 18,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b7cc0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 19,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b7ea0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 0,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b7450> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 1,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b79f0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 2,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 1@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b7ae0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 3,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b7c70> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 4,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b7810> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 5,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b7860> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 6,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 1@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b7720> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 7,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b73b0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 8,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@### 2@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b70e0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 9,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b72c0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 10,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@# 1@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x17758ec20> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 11,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b5ef0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 12,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@### 2@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b5b80> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 13,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b5d60> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 14,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 1@@@@@@### 2@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b5860> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 15,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b5450> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 16,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 1@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b5540> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 17,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b55e0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 18,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b5900> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 19,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   }]},\n",
+       " {'choices': [<OpenAIObject at 0x2967e4f90> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 0,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b8c20> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 1,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@N### 2@@@C#\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b8f40> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 2,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@C@@@C@@@C\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b8d60> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 3,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C3=CC=C(\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b8b30> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 4,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 1@@@C3@@@C4@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b8bd0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 5,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C3@@@C4@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967b8a40> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 6,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@1@@@2@@@3\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x1772ac680> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 7,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@ 1@@@ 1\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x1772ac770> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 8,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@ 1@@@ 1\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x1772ac900> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 9,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C#N@@@C#\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x1772acbd0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 10,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C3=CC=C(\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x1772ac450> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 11,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@C3=CC=C(\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x1772acdb0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 12,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@C3=CC=C(\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x1772aca40> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 13,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 1@@@C3@@@C4@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a8db0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 14,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@C5@@@C\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a8e00> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 15,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C3=CC=C(\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a80e0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 16,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@ 1@@@ 2\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a89a0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 17,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 1@@@C3=CC=C(\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a8720> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 18,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@C### 2@@@C@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a8c70> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 19,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C3=CC=C(\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a71d0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 0,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C(C=C2)\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a72c0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 1,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@C3@@@C4@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7360> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 2,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 1@@@1@@@CC=C(\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7400> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 3,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@C3@@@C4@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7900> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 4,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@ 1@@@ 1\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7b30> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 5,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C3@@@C4@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7bd0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 6,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 0@@@ 1@@@ 2\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7d10> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 7,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@C3@@@C4@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7e00> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 8,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@C3=CC([H])\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7f40> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 9,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C3=CC=C(\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7ea0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 10,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@C@@@C@@@C\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7a40> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 11,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C2@@@C#N\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a76d0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 12,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@C### 2@@@C@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7810> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 13,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C3=CC=C(\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7950> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 14,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 1@@@ 0@@@ 1@@@ 1\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a74f0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 15,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C3=CC=C(\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7590> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 16,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C3=CC=C(\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7720> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 17,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 0@@@ 1@@@ 2\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7630> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 18,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C3=CC=C(\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967a7180> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 19,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@C3@@@C4@@\"\n",
+       "   }]},\n",
+       " {'choices': [<OpenAIObject at 0x2967e45e0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 0,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967e4270> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 1,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967e4130> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 2,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@ 2@@@ 3\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967e41d0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 3,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967e2ea0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 4,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967e2400> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 5,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967e2270> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 6,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@ 1@@@ 1\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967dd0e0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 7,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 4@@@ 1@@@ 2@@@ 1\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967dd2c0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 8,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 4@@@ 1@@@ 2@@@ 1\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967dd360> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 9,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967dd590> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 10,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967dd770> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 11,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@ 2@@@ 3\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967ddf90> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 12,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@@@@ 1@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967ddcc0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 13,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d8220> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 14,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d8720> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 15,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d87c0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 16,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 3@@@ 1@@@ 2@@@ 1\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d88b0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 17,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d89a0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 18,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@ 2@@@ 2\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d8f90> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 19,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d8d60> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 0,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d8e00> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 1,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@@@@ 2@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d8a40> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 2,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 1@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d8b30> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 3,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@@@@ 2@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d8e50> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 4,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 4@@@ 1@@@ 2@@@ 1\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d8680> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 5,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d8400> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 6,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 1@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d8590> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 7,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@ 2@@@ 2\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967d8310> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 8,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 3@@@ 1@@@ 2@@@ 1\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2966f1c70> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 9,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x29665eb30> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 10,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@ 2@@@ 2\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967c3d60> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 11,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967c3e50> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 12,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@ 2@@@ 2\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967c3ae0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 13,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967c36d0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 14,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@@@@ 1@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967c3860> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 15,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967c3b30> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 16,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967c3b80> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 17,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 2@@@ 1@@@@@@ 1@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967c35e0> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 18,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@@@@@@@@@\"\n",
+       "   },\n",
+       "   <OpenAIObject at 0x2967c3270> JSON: {\n",
+       "     \"finish_reason\": \"length\",\n",
+       "     \"index\": 19,\n",
+       "     \"logprobs\": null,\n",
+       "     \"text\": \" 0@@@@@@ 1@@@@@@\"\n",
+       "   }]}]"
+      ]
+     },
+     "execution_count": 18,
+     "metadata": {},
+     "output_type": "execute_result"
     }
    ],
    "source": [
-    "models = ensemble_fine_tune(train_prompts, test_prompts)"
+    "completions"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 11,
+   "execution_count": 19,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
-       "(#1) ['ada:ft-lsmoepfl-2022-09-01-10-23-37']"
+       "3"
       ]
      },
-     "execution_count": 11,
+     "execution_count": 19,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
-    "models"
+    "len(completions)"
    ]
   },
   {
@@ -180,7 +931,9 @@
    "execution_count": null,
    "metadata": {},
    "outputs": [],
-   "source": []
+   "source": [
+    "completions"
+   ]
   }
  ],
  "metadata": {
diff --git a/experiments/wandb/latest-run b/experiments/wandb/latest-run
index 884420d..bc99354 120000
--- a/experiments/wandb/latest-run
+++ b/experiments/wandb/latest-run
@@ -1 +1 @@
-run-20220901_123234-ft-2Sepg0SHBs4k7dBvEmETqr0M
\ No newline at end of file
+run-20220901_142114-ft-fQAERqByHSBq4Vkr7xgIwgrH
\ No newline at end of file
diff --git a/gpt3forchem/api_wrappers.py b/gpt3forchem/api_wrappers.py
index 392a7f5..e2110bd 100644
--- a/gpt3forchem/api_wrappers.py
+++ b/gpt3forchem/api_wrappers.py
@@ -17,6 +17,7 @@ from typing import List
 from functools import partial
 import pandas as pd
 from fastcore.basics import chunked
+import concurrent.futures # fastcore parallel fails for partial functions (https://github.com/fastai/fastcore/pull/294)
 
 # %% ../notebooks/01_api_wrappers.ipynb 5
 def fine_tune(
@@ -26,6 +27,7 @@ def fine_tune(
     n_epochs: int = 4,  # number of epochs to fine-tune for
 ):
     """Run the fine tuning of a GPT-3 model via the OpenAI API."""
+    modelname = None
     result = subprocess.run(
         f"openai api fine_tunes.create -t {train_file} -v {valid_file} -m {model} --n_epochs {n_epochs}",
         shell=True,
@@ -229,9 +231,11 @@ def multiple_query_gpt3(
     one_by_one: bool = False,  # if True, generate one completion at a time (i.e., due to submit the maximum number of prompts per request)
     parallel_max: int = 20,  # maximum number of prompts that can be sent per request
 ):
+    models = [model for model in models if model is not None]
     curried_query = partial(query_gpt3, df=df, temperature=temperature, max_tokens=max_tokens, sleep=sleep, one_by_one=one_by_one, parallel_max=parallel_max)
 
-    completions = parallel(curried_query, models)
+    with concurrent.futures.ProcessPoolExecutor() as executor:
+        completions = executor.map(curried_query, models)
 
-    return completions
+    return list(completions)
 
diff --git a/notebooks/01_api_wrappers.ipynb b/notebooks/01_api_wrappers.ipynb
index c08f062..5826be4 100644
--- a/notebooks/01_api_wrappers.ipynb
+++ b/notebooks/01_api_wrappers.ipynb
@@ -21,7 +21,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 13,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -38,7 +38,8 @@
     "from typing import List\n",
     "from functools import partial\n",
     "import pandas as pd\n",
-    "from fastcore.basics import chunked"
+    "from fastcore.basics import chunked\n",
+    "import concurrent.futures # fastcore parallel fails for partial functions (https://github.com/fastai/fastcore/pull/294)"
    ]
   },
   {
@@ -71,6 +72,7 @@
     "    n_epochs: int = 4,  # number of epochs to fine-tune for\n",
     "):\n",
     "    \"\"\"Run the fine tuning of a GPT-3 model via the OpenAI API.\"\"\"\n",
+    "    modelname = None\n",
     "    result = subprocess.run(\n",
     "        f\"openai api fine_tunes.create -t {train_file} -v {valid_file} -m {model} --n_epochs {n_epochs}\",\n",
     "        shell=True,\n",
@@ -417,11 +419,13 @@
     "    one_by_one: bool = False,  # if True, generate one completion at a time (i.e., due to submit the maximum number of prompts per request)\n",
     "    parallel_max: int = 20,  # maximum number of prompts that can be sent per request\n",
     "):\n",
+    "    models = [model for model in models if model is not None]\n",
     "    curried_query = partial(query_gpt3, df=df, temperature=temperature, max_tokens=max_tokens, sleep=sleep, one_by_one=one_by_one, parallel_max=parallel_max)\n",
     "\n",
-    "    completions = parallel(curried_query, models)\n",
+    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
+    "        completions = executor.map(curried_query, models)\n",
     "\n",
-    "    return completions\n"
+    "    return list(completions)\n"
    ]
   },
   {
